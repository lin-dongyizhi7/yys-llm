import gradio as gr
import json
import subprocess
import threading
import time
import os
from pathlib import Path
from datetime import datetime
import psutil

# é¡¹ç›®æ ¹ç›®å½•
ROOT_DIR = Path(__file__).resolve().parents[2]
DATA_DIR = ROOT_DIR / "data"
MODELS_DIR = ROOT_DIR / "models"

class TrainingManager:
    """è®­ç»ƒç®¡ç†å™¨"""
    
    def __init__(self):
        self.current_training = None
        self.training_process = None
        self.training_logs = []
        self.is_training = False
        
    def start_training(self, base_model, dataset, role, output_dir, epochs, batch_size, lr, cutoff_len, quant):
        """å¯åŠ¨è®­ç»ƒ"""
        if self.is_training:
            return "å·²æœ‰è®­ç»ƒä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œè¯·ç­‰å¾…å®Œæˆã€‚"
        
        # éªŒè¯å‚æ•°
        if not base_model or not dataset or not role or not output_dir:
            return "è¯·å¡«å†™æ‰€æœ‰å¿…éœ€çš„å‚æ•°ã€‚"
        
        # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
        dataset_path = Path(dataset)
        if not dataset_path.exists():
            return f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {dataset}"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # æ„å»ºè®­ç»ƒå‘½ä»¤
        cmd = [
            "python", str(ROOT_DIR / "src" / "train" / "train_lora.py"),
            "--base_model", base_model,
            "--dataset", str(dataset_path),
            "--role", role,
            "--output_dir", str(output_path),
            "--epochs", str(epochs),
            "--batch_size", str(batch_size),
            "--lr", str(lr),
            "--cutoff_len", str(cutoff_len),
            "--quant", quant
        ]
        
        try:
            # å¯åŠ¨è®­ç»ƒè¿›ç¨‹
            self.training_process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            self.is_training = True
            self.training_logs = []
            self.current_training = {
                "start_time": datetime.now(),
                "role": role,
                "output_dir": str(output_path),
                "status": "è¿è¡Œä¸­"
            }
            
            # å¯åŠ¨æ—¥å¿—ç›‘æ§çº¿ç¨‹
            threading.Thread(target=self._monitor_training, daemon=True).start()
            
            return f"è®­ç»ƒå·²å¯åŠ¨ï¼è§’è‰²: {role}, è¾“å‡ºç›®å½•: {output_dir}"
            
        except Exception as e:
            return f"å¯åŠ¨è®­ç»ƒå¤±è´¥: {str(e)}"
    
    def _monitor_training(self):
        """ç›‘æ§è®­ç»ƒè¿›ç¨‹"""
        while self.training_process and self.training_process.poll() is None:
            try:
                line = self.training_process.stdout.readline()
                if line:
                    line = line.strip()
                    if line:
                        self.training_logs.append(line)
                        # é™åˆ¶æ—¥å¿—æ•°é‡
                        if len(self.training_logs) > 1000:
                            self.training_logs = self.training_logs[-500:]
            except:
                break
        
        # è®­ç»ƒå®Œæˆ
        if self.training_process:
            return_code = self.training_process.wait()
            self.is_training = False
            
            if return_code == 0:
                self.current_training["status"] = "å®Œæˆ"
                self.current_training["end_time"] = datetime.now()
            else:
                self.current_training["status"] = "å¤±è´¥"
                self.current_training["end_time"] = datetime.now()
    
    def stop_training(self):
        """åœæ­¢è®­ç»ƒ"""
        if self.training_process and self.is_training:
            self.training_process.terminate()
            self.is_training = False
            return "è®­ç»ƒå·²åœæ­¢"
        return "æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„è®­ç»ƒä»»åŠ¡"
    
    def get_training_status(self):
        """è·å–è®­ç»ƒçŠ¶æ€"""
        if not self.current_training:
            return "æ— è®­ç»ƒä»»åŠ¡", []
        
        status = self.current_training["status"]
        if self.is_training:
            status = "è¿è¡Œä¸­"
        
        return status, self.training_logs[-50:]  # è¿”å›æœ€è¿‘50è¡Œæ—¥å¿—
    
    def get_system_info(self):
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            # GPU ä¿¡æ¯
            gpu_info = "ä¸å¯ç”¨"
            try:
                import torch
                if torch.cuda.is_available():
                    gpu_memory_allocated = torch.cuda.memory_allocated(0) / 1024**3
                    gpu_memory_reserved = torch.cuda.memory_reserved(0) / 1024**3
                    gpu_info = f"{gpu_memory_allocated:.2f}GB / {gpu_memory_reserved:.2f}GB"
            except:
                pass
            
            return {
                "CPU": f"{cpu_percent:.1f}%",
                "å†…å­˜": f"{memory.percent:.1f}% ({memory.used/1024**3:.1f}GB/{memory.total/1024**3:.1f}GB)",
                "ç£ç›˜": f"{disk.percent:.1f}%",
                "GPU": gpu_info
            }
        except Exception as e:
            return {"é”™è¯¯": str(e)}

def get_available_datasets():
    """è·å–å¯ç”¨çš„æ•°æ®é›†"""
    datasets = []
    if DATA_DIR.exists():
        for file in DATA_DIR.rglob("*.jsonl"):
            datasets.append(str(file.relative_to(ROOT_DIR)))
    return datasets

def get_available_models():
    """è·å–å¯ç”¨çš„åŸºç¡€æ¨¡å‹"""
    return [
        "Qwen/Qwen2-1.5B-Instruct",
        "Qwen/Qwen2-7B-Instruct", 
        "Qwen/Qwen2-14B-Instruct",
        "microsoft/DialoGPT-medium",
        "sshleifer/tiny-gpt2"
    ]

def get_training_history():
    """è·å–è®­ç»ƒå†å²"""
    history = []
    if MODELS_DIR.exists():
        for model_dir in MODELS_DIR.iterdir():
            if model_dir.is_dir():
                meta_file = model_dir / "meta.json"
                if meta_file.exists():
                    try:
                        with open(meta_file, 'r', encoding='utf-8') as f:
                            meta = json.load(f)
                            history.append({
                                "è§’è‰²": meta.get("role", "æœªçŸ¥"),
                                "åŸºç¡€æ¨¡å‹": meta.get("base_model", "æœªçŸ¥"),
                                "å®Œæˆæ—¶é—´": meta.get("completed_at", "æœªçŸ¥"),
                                "è®­ç»ƒæ—¶é—´": f"{meta.get('training_time', 0)/3600:.2f}å°æ—¶",
                                "çŠ¶æ€": "å®Œæˆ"
                            })
                    except:
                        pass
    return history

# åˆ›å»ºè®­ç»ƒç®¡ç†å™¨å®ä¾‹
training_manager = TrainingManager()

def create_training_interface():
    """åˆ›å»ºè®­ç»ƒç•Œé¢"""
    
    with gr.Blocks(title="yys-chat æ¨¡å‹è®­ç»ƒ", theme=gr.themes.Soft()) as interface:
        gr.Markdown("# ğŸš€ yys-chat æ¨¡å‹è®­ç»ƒç•Œé¢")
        gr.Markdown("é…ç½®è®­ç»ƒå‚æ•°ï¼Œå¯åŠ¨ LoRA/QLoRA å¾®è°ƒè®­ç»ƒ")
        
        with gr.Row():
            with gr.Column(scale=2):
                # è®­ç»ƒé…ç½®åŒºåŸŸ
                with gr.Group("ğŸ“‹ è®­ç»ƒé…ç½®"):
                    base_model = gr.Dropdown(
                        choices=get_available_models(),
                        value="Qwen/Qwen2-1.5B-Instruct",
                        label="åŸºç¡€æ¨¡å‹",
                        info="é€‰æ‹©è¦å¾®è°ƒçš„åŸºç¡€æ¨¡å‹"
                    )
                    
                    dataset = gr.Dropdown(
                        choices=get_available_datasets(),
                        value="data/yys/train.jsonl",
                        label="è®­ç»ƒæ•°æ®é›†",
                        info="é€‰æ‹©è®­ç»ƒæ•°æ®æ–‡ä»¶"
                    )
                    
                    role = gr.Textbox(
                        value="Mentor",
                        label="è§’è‰²åç§°",
                        info="ä¸ºè®­ç»ƒçš„è§’è‰²æŒ‡å®šä¸€ä¸ªåç§°"
                    )
                    
                    output_dir = gr.Textbox(
                        value="models/yys_mentor",
                        label="è¾“å‡ºç›®å½•",
                        info="æ¨¡å‹å’Œæ—¥å¿—çš„ä¿å­˜ä½ç½®"
                    )
                
                with gr.Group("âš™ï¸ è®­ç»ƒå‚æ•°"):
                    with gr.Row():
                        epochs = gr.Slider(
                            minimum=1, maximum=10, value=3, step=1,
                            label="è®­ç»ƒè½®æ•°", info="å®Œæ•´çš„è®­ç»ƒå‘¨æœŸæ•°"
                        )
                        batch_size = gr.Slider(
                            minimum=1, maximum=8, value=2, step=1,
                            label="æ‰¹æ¬¡å¤§å°", info="æ¯æ­¥å¤„ç†çš„æ ·æœ¬æ•°"
                        )
                    
                    with gr.Row():
                        lr = gr.Slider(
                            minimum=1e-5, maximum=1e-3, value=2e-4, step=1e-5,
                            label="å­¦ä¹ ç‡", info="æ¨¡å‹å‚æ•°æ›´æ–°çš„æ­¥é•¿"
                        )
                        cutoff_len = gr.Slider(
                            minimum=512, maximum=4096, value=2048, step=128,
                            label="æœ€å¤§é•¿åº¦", info="è¾“å…¥åºåˆ—çš„æœ€å¤§é•¿åº¦"
                        )
                    
                    quant = gr.Radio(
                        choices=["none", "4bit", "8bit"],
                        value="none",
                        label="é‡åŒ–æ–¹å¼",
                        info="none: ä¸ä½¿ç”¨é‡åŒ–, 4bit/8bit: ä½¿ç”¨ QLoRA"
                    )
                
                with gr.Row():
                    start_btn = gr.Button("ğŸš€ å¼€å§‹è®­ç»ƒ", variant="primary", size="lg")
                    stop_btn = gr.Button("â¹ï¸ åœæ­¢è®­ç»ƒ", variant="stop", size="lg")
                
                status_text = gr.Textbox(
                    label="è®­ç»ƒçŠ¶æ€",
                    interactive=False,
                    lines=2
                )
            
            with gr.Column(scale=1):
                # ç³»ç»Ÿç›‘æ§åŒºåŸŸ
                with gr.Group("ğŸ“Š ç³»ç»Ÿç›‘æ§"):
                    system_info = gr.JSON(
                        label="ç³»ç»Ÿèµ„æº",
                        value=training_manager.get_system_info()
                    )
                    
                    refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°", size="sm")
                
                # è®­ç»ƒå†å²åŒºåŸŸ
                with gr.Group("ğŸ“š è®­ç»ƒå†å²"):
                    history_table = gr.Dataframe(
                        headers=["è§’è‰²", "åŸºç¡€æ¨¡å‹", "å®Œæˆæ—¶é—´", "è®­ç»ƒæ—¶é—´", "çŠ¶æ€"],
                        datatype=["str", "str", "str", "str", "str"],
                        label="å·²å®Œæˆè®­ç»ƒ",
                        value=get_training_history()
                    )
                    
                    refresh_history_btn = gr.Button("ğŸ”„ åˆ·æ–°å†å²", size="sm")
        
        # è®­ç»ƒæ—¥å¿—åŒºåŸŸ
        with gr.Group("ğŸ“ è®­ç»ƒæ—¥å¿—"):
            with gr.Row():
                log_display = gr.Textbox(
                    label="å®æ—¶æ—¥å¿—",
                    lines=20,
                    max_lines=30,
                    interactive=False,
                    show_copy_button=True
                )
            
            with gr.Row():
                clear_log_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºæ—¥å¿—", size="sm")
                export_log_btn = gr.Button("ğŸ’¾ å¯¼å‡ºæ—¥å¿—", size="sm")
        
        # äº‹ä»¶å¤„ç†
        def start_training_wrapper():
            result = training_manager.start_training(
                base_model.value,
                dataset.value,
                role.value,
                output_dir.value,
                int(epochs.value),
                int(batch_size.value),
                float(lr.value),
                int(cutoff_len.value),
                quant.value
            )
            return result
        
        def stop_training_wrapper():
            return training_manager.stop_training()
        
        def update_status():
            status, logs = training_manager.get_training_status()
            log_text = "\n".join(logs) if logs else "æš‚æ— æ—¥å¿—"
            return status, log_text
        
        def refresh_system_info():
            return training_manager.get_system_info()
        
        def refresh_history():
            return get_training_history()
        
        def clear_logs():
            training_manager.training_logs.clear()
            return ""
        
        def export_logs():
            if not training_manager.training_logs:
                return "æ²¡æœ‰æ—¥å¿—å¯å¯¼å‡º"
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"training_logs_{timestamp}.txt"
            log_content = "\n".join(training_manager.training_logs)
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ–‡ä»¶ä¸‹è½½åŠŸèƒ½
            return f"æ—¥å¿—å·²å‡†å¤‡å¯¼å‡º: {filename}\nå…± {len(training_manager.training_logs)} è¡Œ"
        
        # ç»‘å®šäº‹ä»¶
        start_btn.click(
            start_training_wrapper,
            outputs=status_text
        )
        
        stop_btn.click(
            stop_training_wrapper,
            outputs=status_text
        )
        
        refresh_btn.click(
            refresh_system_info,
            outputs=system_info
        )
        
        refresh_history_btn.click(
            refresh_history,
            outputs=history_table
        )
        
        clear_log_btn.click(
            clear_logs,
            outputs=log_display
        )
        
        export_log_btn.click(
            export_logs,
            outputs=status_text
        )
        
        # è‡ªåŠ¨æ›´æ–°çŠ¶æ€
        interface.load(update_status, outputs=[status_text, log_display])
        
        # å®šæ—¶æ›´æ–°
        status_text.change(
            update_status,
            outputs=[status_text, log_display],
            every=5  # æ¯5ç§’æ›´æ–°ä¸€æ¬¡
        )
        
        system_info.change(
            refresh_system_info,
            outputs=system_info,
            every=10  # æ¯10ç§’æ›´æ–°ä¸€æ¬¡
        )
    
    return interface

def main():
    """ä¸»å‡½æ•°"""
    interface = create_training_interface()
    interface.launch(
        server_name="0.0.0.0",
        server_port=7861,
        share=False,
        show_error=True
    )

if __name__ == "__main__":
    main()
